# src/llm_provider.py
"""
LLM Provider –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
–ü–æ–¥–¥–µ—Ä–∂–∫–∞: GigaChat (Sberbank)
Phase 3: –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –∫ –≤–æ–ø—Ä–æ—Å–∞–º
"""
import os
from typing import List, Dict, Optional
from dataclasses import dataclass


@dataclass
class LLMConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LLM"""
    provider: str = "gigachat"  # gigachat, openai, claude
    model: str = "GigaChat"  # GigaChat, GigaChat-Pro, GigaChat-Plus
    api_key: Optional[str] = None
    temperature: float = 0.3  # –ù–∏–∑–∫–∞—è –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
    max_tokens: int = 2000
    verify_ssl: bool = False  # –î–ª—è GigaChat —á–∞—Å—Ç–æ –Ω—É–∂–Ω–æ False
    scope: str = "GIGACHAT_API_PERS"  # –î–ª—è —Ñ–∏–∑–ª–∏—Ü
    use_cache: bool = True  # Phase 3: –í–∫–ª—é—á–∏—Ç—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ


class GigaChatProvider:
    """–ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å GigaChat API"""

    def __init__(self, config: LLMConfig):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GigaChat –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞

        Args:
            config: –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LLM
        """
        self.config = config

        # –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ GigaChat
        try:
            from gigachat import GigaChat
            self.GigaChat = GigaChat
        except ImportError:
            raise ImportError(
                "GigaChat library not installed. "
                "Install with: pip install gigachat"
            )

        # –ü–æ–ª—É—á–µ–Ω–∏–µ API –∫–ª—é—á–∞
        self.api_key = config.api_key or os.getenv("GIGACHAT_CREDENTIALS")
        if not self.api_key:
            raise ValueError(
                "GigaChat API key not found. "
                "Set GIGACHAT_CREDENTIALS environment variable or pass api_key"
            )

        print(f"[INFO] Initializing GigaChat provider")
        print(f"[INFO] Model: {config.model}")
        print(f"[INFO] Scope: {config.scope}")

    def chat(
            self,
            prompt: str,
            system_prompt: Optional[str] = None,
            temperature: Optional[float] = None
    ) -> str:
        """
        –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ GigaChat

        Args:
            prompt: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
            system_prompt: —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            temperature: —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
        """
        import time

        temp = temperature if temperature is not None else self.config.temperature

        # –ü–æ–¥—Å—á–µ—Ç —Ä–∞–∑–º–µ—Ä–∞ –∑–∞–ø—Ä–æ—Å–∞
        prompt_length = len(prompt)
        system_length = len(system_prompt) if system_prompt else 0
        total_chars = prompt_length + system_length

        print(f"\n[GIGACHAT] üöÄ Sending request to GigaChat API")
        print(f"[GIGACHAT] Model: {self.config.model}")
        print(f"[GIGACHAT] Temperature: {temp}")
        print(f"[GIGACHAT] Prompt size: {prompt_length} chars")
        if system_prompt:
            print(f"[GIGACHAT] System prompt size: {system_length} chars")
        print(f"[GIGACHAT] Total size: {total_chars} chars (~{total_chars // 4} tokens)")

        start_time = time.time()

        try:
            with self.GigaChat(
                    credentials=self.api_key,
                    verify_ssl_certs=self.config.verify_ssl,
                    scope=self.config.scope,
                    model=self.config.model
            ) as giga:
                # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π
                messages = []

                if system_prompt:
                    messages.append({
                        "role": "system",
                        "content": system_prompt
                    })

                messages.append({
                    "role": "user",
                    "content": prompt
                })

                # –ó–∞–ø—Ä–æ—Å –∫ API
                print(f"[GIGACHAT] ‚è≥ Waiting for response...")
                response = giga.chat(
                    messages=messages,
                    temperature=temp,
                    max_tokens=self.config.max_tokens
                )

                elapsed = time.time() - start_time
                response_text = response.choices[0].message.content
                response_length = len(response_text)

                print(f"[GIGACHAT] ‚úÖ Response received in {elapsed:.2f}s")
                print(f"[GIGACHAT] Response size: {response_length} chars (~{response_length // 4} tokens)")

                # –ï—Å–ª–∏ –µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
                if hasattr(response, 'usage') and response.usage:
                    print(f"[GIGACHAT] üí∞ Token usage:")
                    print(f"[GIGACHAT]   - Prompt tokens: {response.usage.prompt_tokens}")
                    print(f"[GIGACHAT]   - Completion tokens: {response.usage.completion_tokens}")
                    print(f"[GIGACHAT]   - Total tokens: {response.usage.total_tokens}")

                return response_text

        except Exception as e:
            elapsed = time.time() - start_time
            print(f"[GIGACHAT] ‚ùå Request failed after {elapsed:.2f}s")
            print(f"[GIGACHAT] Error: {e}")
            raise


class LLMProvider:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–∞–∑–Ω—ã–º–∏ LLM"""

    def __init__(self, config: LLMConfig = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞

        Args:
            config: –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LLM (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
        """
        self.config = config or LLMConfig()

        # –í—ã–±–æ—Ä –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
        if self.config.provider == "gigachat":
            self.provider = GigaChatProvider(self.config)
        else:
            raise ValueError(f"Unsupported provider: {self.config.provider}")

        # Phase 3: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫—ç—à–∞
        if self.config.use_cache:
            try:
                from .llm_cache import LLMCache
                self.cache = LLMCache(enabled=True)
                print("[INFO] LLM caching enabled")
            except Exception as e:
                print(f"[WARN] Failed to initialize cache: {e}")
                self.cache = None
        else:
            self.cache = None

    def _chat_with_cache(
            self,
            prompt: str,
            system_prompt: Optional[str] = None,
            temperature: Optional[float] = None
    ) -> str:
        """
        –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º (Phase 3)

        Args:
            prompt: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
            system_prompt: —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            temperature: —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞

        Returns:
            –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ (–∏–∑ –∫—ç—à–∞ –∏–ª–∏ –Ω–æ–≤—ã–π)
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è –∫—ç—à–∞
        cache_config = {
            "model": self.config.model,
            "temperature": temperature or self.config.temperature,
            "system_prompt": system_prompt or ""
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        if self.cache:
            print(f"[CACHE] üîç Checking cache...")
            cached_response = self.cache.get(prompt, cache_config)
            if cached_response:
                print(f"[CACHE] ‚úÖ Cache HIT! Using cached response")
                print(f"[CACHE] üí∞ Tokens saved: ~{len(prompt.split()) + len(cached_response.split())}")
                return cached_response
            else:
                print(f"[CACHE] ‚ùå Cache MISS - will fetch from API")

        # –í—ã–∑—ã–≤–∞–µ–º API
        response = self.provider.chat(prompt, system_prompt, temperature)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
        if self.cache:
            # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ (–≥—Ä—É–±–∞—è)
            tokens_estimate = len(prompt.split()) + len(response.split())
            print(f"[CACHE] üíæ Saving response to cache (~{tokens_estimate} tokens)")
            self.cache.set(prompt, cache_config, response, tokens=tokens_estimate)

        return response

    def generate_overview(self, summaries: List[str], metadata: Dict = None) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±—â–µ–≥–æ –æ–±–∑–æ—Ä–∞ –ª–µ–∫—Ü–∏–∏

        Args:
            summaries: —Å–ø–∏—Å–æ–∫ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            metadata: –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∏ —Ç.–¥.)

        Returns:
            –û–±—â–∏–π –æ–±–∑–æ—Ä –ª–µ–∫—Ü–∏–∏
        """
        print("\n" + "=" * 60)
        print("[LLM] üìù Generating lecture overview")
        print("=" * 60)
        print(f"[LLM] Input: {len(summaries)} summaries")

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        combined_text = "\n\n".join([
            f"–°–µ–≥–º–µ–Ω—Ç {i + 1}: {summary}"
            for i, summary in enumerate(summaries)
        ])

        # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        system_prompt = """–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–æ–∑–¥–∞—Ç—å –∫—Ä–∞—Ç–∫–∏–π, –Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –æ–±–∑–æ—Ä –≤—Å–µ–π –ª–µ–∫—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π –µ—ë —á–∞—Å—Ç–µ–π.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ–±–∑–æ—Ä—É:
- –û–±—ä—ë–º: 3-5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
- –°—Ç—Ä—É–∫—Ç—É—Ä–∞: –û —á—ë–º –ª–µ–∫—Ü–∏—è, –∫–∞–∫–∏–µ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç—Å—è, –∫–∞–∫–∞—è —Ü–µ–ª—å
- –°—Ç–∏–ª—å: –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–π, —è—Å–Ω—ã–π, –±–µ–∑ –≤–æ–¥—ã
- –Ø–∑—ã–∫: —Ä—É—Å—Å–∫–∏–π
- –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π —Ñ—Ä–∞–∑—ã —Ç–∏–ø–∞ "–≤ —ç—Ç–æ–π –ª–µ–∫—Ü–∏–∏", "–ª–µ–∫—Ç–æ—Ä —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—Ç" - –ø–∏—à–∏ –ø—Ä—è–º–æ –æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–∏"""

        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
        user_prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–∏—Ö —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –ª–µ–∫—Ü–∏–∏ —Å–æ–∑–¥–∞–π –æ–±—â–∏–π –æ–±–∑–æ—Ä:

{combined_text}

–û–±–∑–æ—Ä –ª–µ–∫—Ü–∏–∏:"""

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        overview = self._chat_with_cache(
            prompt=user_prompt,
            system_prompt=system_prompt,
            temperature=0.3
        )

        return overview.strip()

    def extract_key_points(self, summaries: List[str], num_points: int = 5) -> List[str]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ–∑–∏—Å–æ–≤

        Args:
            summaries: —Å–ø–∏—Å–æ–∫ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            num_points: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–∑–∏—Å–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ–∑–∏—Å–æ–≤
        """
        print("\n" + "=" * 60)
        print(f"[LLM] üéØ Extracting {num_points} key points")
        print("=" * 60)
        print(f"[LLM] Input: {len(summaries)} summaries")

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        combined_text = "\n\n".join([
            f"–ß–∞—Å—Ç—å {i + 1}: {summary}"
            for i, summary in enumerate(summaries)
        ])

        # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        system_prompt = """–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –≤—ã–¥–µ–ª–∏—Ç—å –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã–µ —Ç–µ–∑–∏—Å—ã –∏–∑ –ª–µ–∫—Ü–∏–∏.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ç–µ–∑–∏—Å–∞–º:
- –ö–∞–∂–¥—ã–π —Ç–µ–∑–∏—Å ‚Äî —ç—Ç–æ –∑–∞–∫–æ–Ω—á–µ–Ω–Ω–∞—è –º—ã—Å–ª—å (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
- –¢–µ–∑–∏—Å—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–º–∏ –∏ –Ω–µ–ø–æ–≤—Ç–æ—Ä—è—é—â–∏–º–∏—Å—è
- –¢–µ–∑–∏—Å—ã –æ—Ç—Ä–∞–∂–∞—é—Ç –°–£–¢–¨, –∞ –Ω–µ –¥–µ—Ç–∞–ª–∏
- –§–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ —á—ë—Ç–∫–∏–µ –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ
- –ë–µ–∑ –≤–≤–æ–¥–Ω—ã—Ö —Å–ª–æ–≤ —Ç–∏–ø–∞ "–ª–µ–∫—Ç–æ—Ä –≥–æ–≤–æ—Ä–∏—Ç –æ —Ç–æ–º, —á—Ç–æ..."

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
1. [–ü–µ—Ä–≤—ã–π —Ç–µ–∑–∏—Å]
2. [–í—Ç–æ—Ä–æ–π —Ç–µ–∑–∏—Å]
...–∏ —Ç–∞–∫ –¥–∞–ª–µ–µ"""

        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
        user_prompt = f"""–ò–∑ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –ª–µ–∫—Ü–∏–∏ –≤—ã–¥–µ–ª–∏ {num_points} —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö —Ç–µ–∑–∏—Å–æ–≤:

{combined_text}

–ö–ª—é—á–µ–≤—ã–µ —Ç–µ–∑–∏—Å—ã:"""

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        response = self._chat_with_cache(
            prompt=user_prompt,
            system_prompt=system_prompt,
            temperature=0.3
        )

        # –ü–∞—Ä—Å–∏–Ω–≥ —Ç–µ–∑–∏—Å–æ–≤
        key_points = []
        for line in response.strip().split('\n'):
            line = line.strip()
            # –£–¥–∞–ª—è–µ–º –Ω—É–º–µ—Ä–∞—Ü–∏—é (1., 2., - –∏ —Ç.–¥.)
            if line and (line[0].isdigit() or line.startswith('-')):
                # –£–±–∏—Ä–∞–µ–º –Ω–æ–º–µ—Ä –∏ —Ç–æ—á–∫—É/—Ç–∏—Ä–µ
                point = line.lstrip('0123456789.-) ').strip()
                if point:
                    key_points.append(point)

        return key_points[:num_points]

    def generate_questions(
            self,
            summaries: List[str],
            num_questions: int = 10,
            difficulty_mix: bool = True,
            with_answers: bool = True  # Phase 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤
    ) -> List[Dict[str, str]]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∏

        Args:
            summaries: —Å–ø–∏—Å–æ–∫ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            num_questions: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤
            difficulty_mix: –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã —Ä–∞–∑–Ω–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ (easy, medium, hard)
            with_answers: –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç—ã –∫ –≤–æ–ø—Ä–æ—Å–∞–º (Phase 3)

        Returns:
            –°–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ (–∏ –æ—Ç–≤–µ—Ç–∞–º–∏, –µ—Å–ª–∏ with_answers=True)
        """
        print("\n" + "=" * 60)
        print(f"[LLM] ‚ùì Generating {num_questions} questions")
        print("=" * 60)
        print(f"[LLM] Input: {len(summaries)} summaries")
        print(f"[LLM] With answers: {with_answers}")
        print(f"[LLM] Difficulty mix: {difficulty_mix}")

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
        combined_text = "\n\n".join([
            f"–†–∞–∑–¥–µ–ª {i + 1}: {summary}"
            for i, summary in enumerate(summaries)
        ])

        # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        if with_answers:
            system_prompt = """–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–æ–∑–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏ –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏.

–ò—Å–ø–æ–ª—å–∑—É–π —Ç–∞–∫—Å–æ–Ω–æ–º–∏—é –ë–ª—É–º–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏:
- EASY (–±–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å): –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ, –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ñ–∞–∫—Ç–æ–≤
- MEDIUM (–ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ): –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –∞–Ω–∞–ª–∏–∑, –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π
- HARD (—Å–∏–Ω—Ç–µ–∑): –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Ü–µ–Ω–∫—É, —Å–∏–Ω—Ç–µ–∑, –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –≤–æ–ø—Ä–æ—Å–∞–º:
- –í–æ–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –∏ –æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã–º–∏
- –ò–∑–±–µ–≥–∞–π –≤–æ–ø—Ä–æ—Å–æ–≤ —Ç–∏–ø–∞ "–¥–∞/–Ω–µ—Ç"
- –í–æ–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –ø—Ä–æ–≤–µ—Ä—è—Ç—å –ø–æ–Ω–∏–º–∞–Ω–∏–µ, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ —Ñ–∞–∫—Ç—ã
- –û—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫—Ä–∞—Ç–∫–∏–º–∏ –∏ —Ç–æ—á–Ω—ã–º–∏
- –û–±—ä—è—Å–Ω–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã –ø–æ–º–æ–≥–∞—Ç—å –ø–æ–Ω—è—Ç—å —Å—É—Ç—å

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (—Å—Ç—Ä–æ–≥–æ —Å–æ–±–ª—é–¥–∞–π):
[EASY] –í–æ–ø—Ä–æ—Å?
–û–¢–í–ï–¢: –ö—Ä–∞—Ç–∫–∏–π –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç.
–û–ë–™–Ø–°–ù–ï–ù–ò–ï: –ü–æ—è—Å–Ω–µ–Ω–∏–µ, –ø–æ—á–µ–º—É —ç—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç.

[MEDIUM] –í–æ–ø—Ä–æ—Å?
–û–¢–í–ï–¢: –ö—Ä–∞—Ç–∫–∏–π –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç.
–û–ë–™–Ø–°–ù–ï–ù–ò–ï: –ü–æ—è—Å–Ω–µ–Ω–∏–µ.

...–∏ —Ç–∞–∫ –¥–∞–ª–µ–µ"""
        else:
            system_prompt = """–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–æ–∑–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é –ª–µ–∫—Ü–∏–∏.

–ò—Å–ø–æ–ª—å–∑—É–π —Ç–∞–∫—Å–æ–Ω–æ–º–∏—é –ë–ª—É–º–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏:
- EASY (–±–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å): –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –∑–∞–ø–æ–º–∏–Ω–∞–Ω–∏–µ, –ø–æ–Ω–∏–º–∞–Ω–∏–µ —Ñ–∞–∫—Ç–æ–≤
- MEDIUM (–ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ): –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –∞–Ω–∞–ª–∏–∑, –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π
- HARD (—Å–∏–Ω—Ç–µ–∑): –≤–æ–ø—Ä–æ—Å—ã –Ω–∞ –æ—Ü–µ–Ω–∫—É, —Å–∏–Ω—Ç–µ–∑, –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
[EASY] –í–æ–ø—Ä–æ—Å?
[MEDIUM] –í–æ–ø—Ä–æ—Å?
[HARD] –í–æ–ø—Ä–æ—Å?"""

        # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç
        difficulty_instruction = ""
        if difficulty_mix:
            easy_count = num_questions // 3
            medium_count = num_questions // 3
            hard_count = num_questions - easy_count - medium_count
            difficulty_instruction = f"""
–°–æ–∑–¥–∞–π {num_questions} –≤–æ–ø—Ä–æ—Å–æ–≤ –≤ —Ç–∞–∫–æ–º —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–∏:
- {easy_count} –≤–æ–ø—Ä–æ—Å–æ–≤ —É—Ä–æ–≤–Ω—è EASY
- {medium_count} –≤–æ–ø—Ä–æ—Å–æ–≤ —É—Ä–æ–≤–Ω—è MEDIUM
- {hard_count} –≤–æ–ø—Ä–æ—Å–æ–≤ —É—Ä–æ–≤–Ω—è HARD"""
        else:
            difficulty_instruction = f"–°–æ–∑–¥–∞–π {num_questions} –≤–æ–ø—Ä–æ—Å–æ–≤ —Ä–∞–∑–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏."

        user_prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –ª–µ–∫—Ü–∏–∏ —Å–æ–∑–¥–∞–π –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è —Å–∞–º–æ–ø—Ä–æ–≤–µ—Ä–∫–∏:

{combined_text}

{difficulty_instruction}

–í–æ–ø—Ä–æ—Å—ã:"""

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        response = self._chat_with_cache(
            prompt=user_prompt,
            system_prompt=system_prompt,
            temperature=0.5  # –ß—É—Ç—å –≤—ã—à–µ –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
        )

        # –ü–∞—Ä—Å–∏–Ω–≥ –≤–æ–ø—Ä–æ—Å–æ–≤
        questions = []
        current_question = None
        current_answer = None
        current_explanation = None

        for line in response.strip().split('\n'):
            line = line.strip()
            if not line:
                continue

            # –ü–æ–∏—Å–∫ —É—Ä–æ–≤–Ω—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
            if any(tag in line.upper() for tag in ["[EASY]", "[MEDIUM]", "[HARD]"]):
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –≤–æ–ø—Ä–æ—Å, –µ—Å–ª–∏ –µ—Å—Ç—å
                if current_question:
                    questions.append({
                        "question": current_question["text"],
                        "difficulty": current_question["difficulty"],
                        "answer": current_answer,
                        "explanation": current_explanation
                    })

                # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å
                difficulty = "medium"
                if "[EASY]" in line.upper():
                    difficulty = "easy"
                elif "[HARD]" in line.upper():
                    difficulty = "hard"

                question_text = line.split(']', 1)[1].strip()
                question_text = question_text.lstrip('0123456789.-) ').strip()

                current_question = {"text": question_text, "difficulty": difficulty}
                current_answer = None
                current_explanation = None

            elif line.upper().startswith("–û–¢–í–ï–¢:"):
                current_answer = line.split(':', 1)[1].strip()

            elif line.upper().startswith("–û–ë–™–Ø–°–ù–ï–ù–ò–ï:"):
                current_explanation = line.split(':', 1)[1].strip()

        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–æ–ø—Ä–æ—Å
        if current_question:
            questions.append({
                "question": current_question["text"],
                "difficulty": current_question["difficulty"],
                "answer": current_answer,
                "explanation": current_explanation
            })

        print(f"\n[LLM] ‚úÖ Successfully parsed {len(questions)} questions")
        if with_answers:
            questions_with_answers = sum(1 for q in questions if q.get('answer'))
            print(f"[LLM] Questions with answers: {questions_with_answers}/{len(questions)}")

        return questions[:num_questions]


def main():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    config = LLMConfig(
        provider="gigachat",
        model="GigaChat",
        api_key=os.getenv("GIGACHAT_CREDENTIALS"),
        temperature=0.3,
        use_cache=True  # Phase 3: –í–∫–ª—é—á–∏—Ç—å –∫—ç—à
    )

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
    llm = LLMProvider(config)

    # –ü—Ä–∏–º–µ—Ä —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–π
    example_summaries = [
        "–í –Ω–∞—á–∞–ª–µ –ª–µ–∫—Ü–∏–∏ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç—Å—è –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã –æ–±—ä–µ–∫—Ç–Ω–æ-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è.",
        "–î–∞–ª–µ–µ –æ–±—ä—è—Å–Ω—è–µ—Ç—Å—è –∫–æ–Ω—Ü–µ–ø—Ü–∏—è –∏–Ω–∫–∞–ø—Å—É–ª—è—Ü–∏–∏ –∏ –µ—ë –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ.",
        "–í –∑–∞–∫–ª—é—á–µ–Ω–∏–µ –æ–±—Å—É–∂–¥–∞—é—Ç—Å—è –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ."
    ]

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è overview
    print("\n=== OVERVIEW ===")
    overview = llm.generate_overview(example_summaries)
    print(overview)

    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ–∑–∏—Å–æ–≤
    print("\n=== KEY POINTS ===")
    key_points = llm.extract_key_points(example_summaries, num_points=3)
    for i, point in enumerate(key_points, 1):
        print(f"{i}. {point}")

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–æ–≤ —Å –æ—Ç–≤–µ—Ç–∞–º–∏ (Phase 3)
    print("\n=== QUESTIONS WITH ANSWERS ===")
    questions = llm.generate_questions(example_summaries, num_questions=3, with_answers=True)
    for q in questions:
        print(f"\n[{q['difficulty'].upper()}] {q['question']}")
        if q.get('answer'):
            print(f"  –û—Ç–≤–µ—Ç: {q['answer']}")
        if q.get('explanation'):
            print(f"  –û–±—ä—è—Å–Ω–µ–Ω–∏–µ: {q['explanation']}")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞
    if llm.cache:
        stats = llm.cache.get_stats()
        print(f"\n=== CACHE STATS ===")
        print(f"Entries: {stats['total_entries']}")
        print(f"Estimated tokens saved: {stats['estimated_tokens_saved']}")


if __name__ == "__main__":
    main()
